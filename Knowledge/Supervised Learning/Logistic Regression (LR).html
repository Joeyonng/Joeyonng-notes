<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Joeyonng - Logistic Regression (LR)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Joeyonng</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Knowledge</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../Notes/index.html" rel="" target="">
 <span class="menu-text">Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://joeyonng.github.io/joeyonng-backyard/" rel="" target=""><i class="bi bi-House" role="img">
</i> 
 <span class="menu-text">Backyard</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Logistic Regression (LR)</li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Linear Algebra</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/01_Fields_and_Spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fields and Spaces</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/02_Vectors_and_Matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vectors and Matrices</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/03_Span_and_Linear_Independence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Span and Linear Independence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/04_Basis_and_Dimension.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basis and Dimension</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/05_Linear_Map_and_Rank.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Map and Rank</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/06_Inner_Product_and_Norm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inner Product and Norm</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/07_Orthogonality_and_Unitary_Matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Orthogonality and Unitary Matrix</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/08_Complementary_Subspaces_and_Projection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Complementary Subspaces and Projection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/09_Orthogonal_Complement_and_Decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Orthogonal Complement and Decomposition</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/10_URV_Fractorization_and_SVD.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">URV Factorization and SVD</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/11_Pseudoinverse.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Pseudoinverse</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/12_Orthogonal_and_Affine_Projection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Orthogonal and Affine Projection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/13_Determinants_and_Eigensystems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Determinants and Eigensystems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/14_Similarity_and_Diagonalization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Similarity and Diagonalization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Linear Algebra/15_Normal_and_Positive_Definite_Matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Normal and Positive Definite Matrices</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Learning Theory</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Learning Theory/1_Statistical_Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Learning Theory/2_Bayesian_Classifier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Classifier</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Learning Theory/3_Effective_Class_Size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Effective Class Size</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Learning Theory/4_Empirical_Risk_Minimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Empirical Risk Minimization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Learning Theory/5_Uniform_Convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Uniform Convergence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Learning Theory/6_PAC_Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PAC Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../Knowledge/Learning Theory/7_Rademacher_Complexity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rademacher Complexity</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#preliminary" id="toc-preliminary" class="nav-link active" data-scroll-target="#preliminary">Preliminary</a>
  <ul class="collapse">
  <li><a href="#optimization" id="toc-optimization" class="nav-link" data-scroll-target="#optimization">Optimization</a></li>
  </ul></li>
  <li><a href="#linear-regression-for-regression-problems" id="toc-linear-regression-for-regression-problems" class="nav-link" data-scroll-target="#linear-regression-for-regression-problems">## Linear regression for regression problems</a>
  <ul class="collapse">
  <li><a href="#linear-function" id="toc-linear-function" class="nav-link" data-scroll-target="#linear-function">Linear function</a></li>
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function">Loss function</a></li>
  <li><a href="#regularization" id="toc-regularization" class="nav-link" data-scroll-target="#regularization">Regularization</a></li>
  </ul></li>
  <li><a href="#solving-linear-regression" id="toc-solving-linear-regression" class="nav-link" data-scroll-target="#solving-linear-regression">Solving linear regression</a></li>
  <li><a href="#solving-linear-regression-1" id="toc-solving-linear-regression-1" class="nav-link" data-scroll-target="#solving-linear-regression-1">Solving linear regression</a></li>
  <li><a href="#logistic-regression-for-classification-problems" id="toc-logistic-regression-for-classification-problems" class="nav-link" data-scroll-target="#logistic-regression-for-classification-problems">## Logistic regression for classification problems</a>
  <ul class="collapse">
  <li><a href="#from-regression-to-classification-using-sigmoid-function" id="toc-from-regression-to-classification-using-sigmoid-function" class="nav-link" data-scroll-target="#from-regression-to-classification-using-sigmoid-function">From regression to classification using sigmoid function</a></li>
  <li><a href="#binary-cross-entropy-log-loss-instead-of-mean-squared-error" id="toc-binary-cross-entropy-log-loss-instead-of-mean-squared-error" class="nav-link" data-scroll-target="#binary-cross-entropy-log-loss-instead-of-mean-squared-error">Binary cross entropy (log loss) instead of mean squared error</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Logistic Regression (LR)</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<hr>
<ol type="1">
<li>Linear regression is a supervised machine learning model that fits a correlation linear line between input and label variables. The output value can be arbitrary continuous value and thus it is used for regression.</li>
<li>The model has a weight vector and a bias as parameters. The output of the model is the dot product of the weight vector and the input vector plus a bias value.</li>
<li>The linear regression model is trained by solving an optimization problem that is defined by applying a cost function that evaluates the difference between the model’s output and the correct labels. The cost function for linear regression is mean squared error function that takes the mean of the squared value of each prediction’s error. MSE for linear regression is proved to be convex, so solving it using convex optimization or gradient descent will get the global minimum.</li>
<li>Logistic regression is similar to linear regression, but the output is a probability value between 0 and 1, so it is used for binary classification instead of regression.</li>
<li>A sigmoid (logistic) function is attached after the output of linear regression to output a probability for logistic regression. Instead of using MSE, the cost function is changed to binary cross entropy such that the loss grows exponentially with the difference between outputs and labels.</li>
</ol>
<section id="preliminary" class="level2">
<h2 class="anchored" data-anchor-id="preliminary">Preliminary</h2>
<hr>
<section id="optimization" class="level3">
<h3 class="anchored" data-anchor-id="optimization">Optimization</h3>
<section id="convex-function" class="level4">
<h4 class="anchored" data-anchor-id="convex-function">Convex function</h4>
<blockquote class="blockquote">
<p>TODO</p>
</blockquote>
</section>
<section id="gradient-descent" class="level4">
<h4 class="anchored" data-anchor-id="gradient-descent">Gradient descent</h4>
<blockquote class="blockquote">
<p>TODO</p>
</blockquote>
</section>
</section>
</section>
<section id="linear-regression-for-regression-problems" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-for-regression-problems">## Linear regression for regression problems</h2>
<section id="linear-function" class="level3">
<h3 class="anchored" data-anchor-id="linear-function">Linear function</h3>
<p>If a function with single input and output <span class="math inline">y = f(x)</span> is a linear function, it represents a straight line on the coordinate plane. Thus it has the form:</p>
<p><span class="math display"> y = wx + b </span></p>
<p>where <span class="math inline">w</span> is the slope and <span class="math inline">b</span> is the y-intercept of the line.</p>
<p>A linear function can also take multiple inputs and we can represent <span class="math inline">n</span> inputs with a vector <span class="math inline">\mathbf{x} \in \mathbb{R}^{d}</span>. Then the equation changes to:</p>
<p><span class="math display"> y = \mathbf{w} \cdot \mathbf{x} + b </span></p>
<p>where <span class="math inline">\mathbf{w} \in \mathbb{R}^{d}</span> is called <strong>weights</strong> or the weight vector and <span class="math inline">b \in \mathbb{R}</span> is called <strong>bias</strong>.</p>
<p>Linear regression is a supervised regression model that simply fits a linear function between the inputs <span class="math inline">\mathbf{x}</span> and output <span class="math inline">y</span>.</p>
</section>
<section id="loss-function" class="level3">
<h3 class="anchored" data-anchor-id="loss-function">Loss function</h3>
<p>Loss function is a function that measures the error between the labels predicted by your current model and the true labels for a set of instances (training set).</p>
<p>Linear regression minimizes the a particular loss function called <strong>mean squared error (MSE)</strong> function. Given a set of training labels <span class="math inline">\mathbf{y} = y_{1}, y_{2}, \dots, y_{n}</span> for <span class="math inline">n</span> training instances and the predicted labels <span class="math inline">\hat{\mathbf{y}} = \hat{y}_{1}, \hat{y}_{2}, \dots, \hat{y}_{n}</span> for the same instances, MSE is defined as:</p>
<p><span class="math display"> \operatorname{MSE}(\hat{\mathbf{y}}, \mathbf{y}) = \frac{1}{n} \sum_{i}^{n}(\hat{y}_{i} - y_{i})^{2} </span></p>
<p>Thus, fitting a linear regression model for a training set <span class="math inline">\mathbf{X} \in \mathbb{R}^{n \times d}</span> with labels <span class="math inline">\mathbf{y} \in \mathbb{R}^{n}</span> is a convex optimization problem:</p>
<p><span class="math display">
\begin{align}
\min &amp; \quad \lVert (\mathbf{X}\mathbf{w} + b) - \mathbf{y} \rVert_{2}^{2} \\
= \min &amp; \quad \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} \\
\end{align}
</span></p>
</section>
<section id="regularization" class="level3">
<h3 class="anchored" data-anchor-id="regularization">Regularization</h3>
<p>Regularization is a technique used to avoid over-fitting of the machine learning models. Regularization works by adding an additional penalty term in the loss function to penalize aspects of the model other than the prediction error.</p>
<p><span class="math display"> L_{\text{new}} = L_{\text{old}} + \lambda L_{\text{reg}} </span></p>
<p>where <span class="math inline">\lambda</span> is a hyperparamter that adjust the trade-off between the primary objective and the regularization.</p>
<p>For linear regression and other many models, usually <span class="math inline">L_{2}</span> regularization (Ridge) and <span class="math inline">L_{1}</span> regularization (Lasso) are used. - Ridge penalizes the <span class="math inline">L_{2}</span> norm of the weights</p>
<p><span class="math display">
\begin{align}
L_{\text{ridge}} &amp; = \lVert \mathbf{w} \rVert_{2}^{2} \\
&amp; = \sum_{i=1}^{\lvert \mathbf{w} \rvert} w_{i}^{2} \\
\end{align}
</span></p>
<ul>
<li>Lasso penalizes the <span class="math inline">L_{1}</span> norm of the weights</li>
</ul>
<p><span class="math display">
\begin{align}
L_{\text{lasso}} &amp; = \lVert \mathbf{w} \rVert_{1} \\
&amp; = \sum_{i=1}^{\lvert \mathbf{w} \rvert} \lvert w_{i} \rvert \\
\end{align}
</span></p>
<p>Both Ridge and Lasso penalize the magnitude of the weights. Large weights tend to overfit the training dataset because &gt; TODO</p>
</section>
</section>
<section id="solving-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="solving-linear-regression">Solving linear regression</h2>
<hr>
<p>Here we show how we can analytically solve linear regression to get a closed form solution.</p>
<p>We first make <span class="math inline">b</span> as part of <span class="math inline">\mathbf{w}</span> to simplify the derivation process, which is done by adding <span class="math inline">b</span> as an extra weight into <span class="math inline">\mathbf{w}</span> vector. The result weight vector <span class="math inline">\mathbf{\hat{w}} \in \mathbb{R}^{d + 1}</span> has one extra dimension:</p>
<p><span class="math display"> \mathbf{\hat{w}} = (b, w_{1}, w_{2}, \dots, w_{d}). </span></p>
<p>Then we add a dummy input <span class="math inline">x_{0} = 1</span> to all input instances, so that</p>
<p><span class="math display"> \mathbf{\hat{x}} = (1, x_{1}, x_{2}, \dots, x_{d}). </span></p>
<p>As a result, we have</p>
<p><span class="math display"> \mathbf{\hat{w}} \cdot \mathbf{\hat{x}} = \mathbf{w} \cdot \mathbf{x} + b. </span></p>
<p>The equation that we want to solve is</p>
<p><span class="math display"> \min \quad \frac{1}{n} \sum_{i=1}^{n} (\mathbf{\hat{w}} \cdot \mathbf{\hat{x}}_{i} - y_{i})^{2} + \lambda \lVert \mathbf{w} \rVert_{2}^{2} </span></p>
<p>Since this equation is a convex function, it can be directly solved by setting its derivative w.r.t its parameters (<span class="math inline">\mathbf{\hat{w}})</span> to 0.</p>
</section>
<section id="solving-linear-regression-1" class="level2">
<h2 class="anchored" data-anchor-id="solving-linear-regression-1">Solving linear regression</h2>
<p>Here we show how we can analytically solve linear regression with <span class="math inline">L_{2}</span> regularization to get a closed form solution.</p>
<p><span class="math display"> \min \quad \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} + \lambda \lVert \mathbf{w} \rVert_{2}^{2} </span></p>
<p>Since this equation is a convex function, it can be directly solved by taking its derivative w.r.t its parameters (<span class="math inline">\mathbf{w}</span> and <span class="math inline">b</span>).</p>
<p><span class="math display">
\begin{align}
\frac{\partial}{\partial \mathbf{w}_{j}} \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial \mathbf{w}_{j}} \frac{1}{n} \sum_{i=1}^{n} (\mathbf{w} \cdot \mathbf{x}_{i} + (b - y_{i}))^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{2}{n} \sum_{i=1}^{n} \mathbf{x}_{i, j} (\mathbf{w} \cdot \mathbf{x}_{i} + (b - y_{i})) + 2 \lambda \mathbf{w}_{j} &amp; = 0 \\
\end{align}
</span></p>
<p><span class="math display">
\begin{align}
\frac{\partial}{\partial \mathbf{w}} \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial \mathbf{w}} \frac{1}{n} \sum_{i=1}^{n} (\mathbf{w} \cdot \mathbf{x}_{i} + (b - y_{i}))^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial \mathbf{w}} \frac{1}{n} \sum_{i=1}^{n} (\mathbf{w} \cdot \mathbf{x}_{i})^{2} + 2(\mathbf{w} \cdot \mathbf{x}_{i})(b - y_{i}) + (b - y_{i})^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{1}{n} \sum_{i=1}^{n} 2(\mathbf{x}_{i} \cdot \mathbf{x}_{i})\mathbf{w} + 2\mathbf{x}_{i}(b - y_{i}) + 2 \lambda \mathbf{w} &amp; = 0\\
\frac{2 \mathbf{w}}{n} \sum_{i=1}^{n} \mathbf{x}_{i} \cdot \mathbf{x}_{i} + \frac{2b}{n} \sum_{i=1}^{n} \mathbf{x}_{i} - \frac{2}{n} \sum_{i=1}^{n} \mathbf{x}_{i} y_{i} + 2 \lambda \mathbf{w} &amp; = 0 \\
\end{align}
</span></p>
<blockquote class="blockquote">
<p>TODO</p>
</blockquote>
<p><span class="math display">
\begin{align}
\frac{\partial}{\partial b} \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} + \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial b} \frac{1}{n} \sum_{i=1}^{n} (b + (\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}))^{2} + \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial b} \frac{1}{n} \sum_{i=1}^{n} b^{2} + 2b(\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}) + (\mathbf{w} \cdot \mathbf{x}_{i} - y_{i})^{2} + \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{1}{n} \sum_{i=1}^{n} 2b + 2(\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}) &amp; = 0 \\
2b + \frac{2}{n} \sum_{i=1}^{n} （\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}) &amp; = 0 \\
b &amp; = - \frac{1}{n} \sum_{i=1}^{n} （\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}) \\
\end{align}
</span></p>
</section>
<section id="logistic-regression-for-classification-problems" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-for-classification-problems">## Logistic regression for classification problems</h2>
<section id="from-regression-to-classification-using-sigmoid-function" class="level3">
<h3 class="anchored" data-anchor-id="from-regression-to-classification-using-sigmoid-function">From regression to classification using sigmoid function</h3>
<p>How can we use linear regression on a binary classification problem where the labels are 0 and 1?</p>
<p>Answer: take the output of a linear regression model and pass it to a <strong>sigmoid</strong> (logistic) function:</p>
<p><span class="math display"> \sigma(x) = \mathrm{sigmoid}(x) = \frac{1}{1 + e^{-x}} </span></p>
<p>Sigmoid function has the following characterstics that are suitable for binary classification 1. Sigmoid function maps range <span class="math inline">(-\inf, \inf)</span> to range <span class="math inline">(0, 1)</span>, which can be interpreted as the possibility of being class 1. 1. Positive inputs map to output larger than 0.5 and negative inputs map to output less than 0.5.</p>
<p>Thus, given an instance <span class="math inline">\mathbf{x}</span>, the binary output can be derived by setting a threshold <span class="math inline">\theta</span> (usually set to <span class="math inline">0.5</span>) to the output of the logistic regression,</p>
<p><span class="math display"> \hat{y} = \sigma(\mathbf{w}\mathbf{x} + b) </span></p>
<p><span class="math display">
\hat{y}_{\text{label}} =
\begin{cases}
1, &amp; \hat{y} \geq \theta \\
0, &amp; \hat{y} &lt; \theta \\
\end{cases}
</span></p>
<p>Note another commonly used function is <strong>logit</strong> function,</p>
<p><span class="math display"> \sigma^{-1}(x) = \mathrm{logit}(x) = \log \frac{x}{1 - x} </span></p>
<p>The inverse of the sigmoid function is the logit function, which can be derived by exchange the input and the output of the sigmoid function:</p>
<p><span class="math display">
\begin{align}
x &amp;= \frac{1}{1 + e^{-y}} \\
\frac{1}{x} &amp;= 1 + e^{-y} \\
e^{-y} &amp;= \frac{1 - x}{x} \\
e^{y} &amp;= \frac{x}{1 - x} \\
y &amp;= \log\frac{x}{1 - x} \\
\end{align}
</span></p>
</section>
<section id="binary-cross-entropy-log-loss-instead-of-mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="binary-cross-entropy-log-loss-instead-of-mean-squared-error">Binary cross entropy (log loss) instead of mean squared error</h3>
<p>Although sigmoid function can work for binary classification problem, it doesn’t work quite well with MSE loss. The primary reason is that MSE with sigmoid function is not a convex function anymore.</p>
<p><span class="math display"> L_{\text{MSE}} = \frac{1}{n} \sum_{i}^{n} (\frac{1}{1 + e^{-(\mathbf{w}\mathbf{x} + b)}} -y_{i})^{2} = \frac{1}{n} \sum_{i}^{n} (\sigma(\mathbf{w}\mathbf{x} + b) -y_{i})^{2} </span></p>
<p>To prove a function is convex or not, one way is to see if the second derivative of <span class="math inline">L_{\text{MSE}}</span> w.r.t to <span class="math inline">\mathbf{w}</span> is positive semidefinite.</p>
<p><span class="math display">
\begin{align}
\frac{\partial L_{\text{MSE}}}{\partial \mathbf{w}} &amp; = \frac{\partial L_{\text{MSE}}}{\partial \sigma} \frac{\partial \sigma}{\partial \mathbf{w}} &amp; \text{[chain rule]} \\
&amp; = \frac{\partial}{\partial \sigma} \left( \frac{1}{n} \sum_{i}^{n} (\sigma -y_{i})^{2} \right) \sigma(1 - \sigma) \mathbf{x} &amp; \text{[$\sigma' = \sigma(1 - \sigma)$]} \\
&amp; = \frac{2}{n} \sum_{i}^{n} (\sigma - y_{i}) \sigma(1 - \sigma) \mathbf{x} \\
&amp; = \frac{2 \mathbf{x}}{n} \sum_{i}^{n} \sigma^{2} - \sigma^{3} - y_{i}\sigma - y_{i}\sigma^{2}  \\
\end{align}
</span></p>
<p><span class="math display">
\begin{align}
\frac{\partial^{2} L_{\text{MSE}}}{\partial \mathbf{w}^{2}} &amp; = \frac{\partial}{\partial \mathbf{w}} \left( \frac{2 \mathbf{x}}{n} \sum_{i}^{n} \sigma^{2} - \sigma^{3} - y_{i}\sigma - y_{i}\sigma^{2} \right) \\
&amp; = \frac{\partial}{\partial \sigma} \left( \frac{2 \mathbf{x}}{n} \sum_{i}^{n} \sigma^{2} - \sigma^{3} - y_{i}\sigma - y_{i}\sigma^{2} \right) \frac{\partial \sigma}{\partial \mathbf{w}}^{T} \\
&amp; = \left( \frac{2 \mathbf{x}}{n} \sum_{i}^{n} 2\sigma - 3\sigma^{2} - y_{i} - 2y_{i}\sigma \right) \sigma(1 - \sigma) \mathbf{x}^{T} \\
\end{align}
</span></p>
<blockquote class="blockquote">
<p>TODO: prove the hessian matrix is not positive semidefinite.</p>
</blockquote>
<p>Thus, instead of MSE, <strong>binary cross entropy</strong> (BCE) loss (log loss) is used with sigmoid to create a convex objective.</p>
<p><span class="math display"> \mathrm{BCE} = -\frac{1}{n}\sum_{i}^{n}(y_{i}\log(\hat{y}_{i}) + (1-y_{i})\log(1-\hat{y}))) </span></p>
<p>BCE assumes both inputs <span class="math inline">y</span> and <span class="math inline">\hat{y}</span> are in the range <span class="math inline">[0, 1]</span>. Since normally the labels <span class="math inline">y_{i}</span> are 0 or 1, BCE can be interpreted by decomposing to two cases for each prediction and label pair:</p>
<p><span class="math display">
\begin{cases}
-\log(\hat{y}_{i}) &amp;  y_{i} = 1 \\
-\log(1 - \hat{y}_{i}) &amp; y_{i} = 0 \\
\end{cases}
</span></p>
<div class="cell" data-tags="[&quot;remove-input&quot;]" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> IFrame</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>IFrame(<span class="st">"https://www.desmos.com/calculator/ojpmcptvt0?embed"</span>, width<span class="op">=</span><span class="dv">500</span>, height<span class="op">=</span><span class="dv">500</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">

        <iframe width="500" height="500" src="https://www.desmos.com/calculator/ojpmcptvt0?embed" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<hr>
<ol type="1">
<li>https://towardsdatascience.com/why-not-mse-as-a-loss-function-for-logistic-regression-589816b5e03c</li>
<li>https://www.cs.toronto.edu/~rgrosse/courses/csc311_f20/readings/notes_on_linear_regression.pdf</li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>