{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf659374-fc34-4abf-950e-b6a04ac90c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders (chapters) to publish\n",
    "CHAPTERS = ['Statistical Learning', 'Learning Theory', 'Supervised Learning']\n",
    "# Only publish numbered files (names that have numbers)\n",
    "NUMBERED_ONLY = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24e0fa4-2ea3-44ea-84f4-f31d253e24fd",
   "metadata": {},
   "source": [
    "## Update toc.yml based on the current file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe77be5-985f-4b3a-ad44-5d4629ee8ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'jb-book',\n",
       " 'root': 'root',\n",
       " 'parts': [{'caption': 'Statistical Learning',\n",
       "   'numbered': 2,\n",
       "   'chapters': [{'title': 'Bayesian Decision Theory',\n",
       "     'file': 'Statistical Learning/1_Bayesian_Decision_Theory'},\n",
       "    {'title': 'Maximum Likelihood Estimation',\n",
       "     'file': 'Statistical Learning/2_Maximum_Likelihood_Estimation'},\n",
       "    {'title': 'Bayesian Estimation',\n",
       "     'file': 'Statistical Learning/3_Bayesian_Estimation'},\n",
       "    {'title': 'Expectation Maximization',\n",
       "     'file': 'Statistical Learning/4_Expectation_Maximization'}]},\n",
       "  {'caption': 'Learning Theory',\n",
       "   'numbered': 2,\n",
       "   'chapters': [{'title': 'Statistical Learning',\n",
       "     'file': 'Learning Theory/1_Statistical_Learning'},\n",
       "    {'title': 'Effective Class Size',\n",
       "     'file': 'Learning Theory/2_Effective_Class_Size'},\n",
       "    {'title': 'PAC Learning', 'file': 'Learning Theory/3_PAC_Learning'},\n",
       "    {'title': 'Agnostic Learning',\n",
       "     'file': 'Learning Theory/4_Agnostic_Learning'},\n",
       "    {'title': 'Rademacher Complexity',\n",
       "     'file': 'Learning Theory/5_Rademacher_Complexity'}]},\n",
       "  {'caption': 'Supervised Learning',\n",
       "   'numbered': 2,\n",
       "   'chapters': [{'title': 'Linear Discriminant',\n",
       "     'file': 'Supervised Learning/0_Linear_Discriminant'},\n",
       "    {'title': 'Perceptron', 'file': 'Supervised Learning/1_Perceptron'},\n",
       "    {'title': 'Logistic Regression',\n",
       "     'file': 'Supervised Learning/2_Logistic_Regression'},\n",
       "    {'title': 'Multi Layer Perceptron',\n",
       "     'file': 'Supervised Learning/3_Multi_Layer_Perceptron'},\n",
       "    {'title': 'Boosting', 'file': 'Supervised Learning/4_Boosting'}]}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "def get_files(path):\n",
    "    # Get all files in the path \n",
    "    entries = {}\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            # Get file name and extension\n",
    "            name = entry.name\n",
    "            name_ext = name.split('.')\n",
    "\n",
    "            # Skip if the entry is a hidden entry (.*) or a jupyter-book entry (_*)\n",
    "            if name.startswith('.') or name.startswith('_'):\n",
    "                continue\n",
    "                \n",
    "            if entry.is_file():\n",
    "                # Save to dict if the file is a ipynb or md\n",
    "                if len(name_ext) > 1 and name_ext[-1] in ['ipynb', 'md']:\n",
    "                    entries[name_ext[0]] = None\n",
    "            else:\n",
    "                # Recursive go into the folder\n",
    "                entries[name_ext[0]] = get_files(os.path.join(path, name))\n",
    "            \n",
    "    return entries\n",
    "\n",
    "def files_to_yaml(dirname, files):\n",
    "    # Sort file names alphabetically\n",
    "    file_folder = sorted(list(files.items()), key=lambda x: x[0])\n",
    "    \n",
    "    # Iterate all ipynb files or folders found by get_files(path)\n",
    "    sub_yaml = []\n",
    "    for key, value in file_folder:\n",
    "        title = key\n",
    "        entry = {}\n",
    "\n",
    "        # Skip the index.ipynb\n",
    "        if key.split('.')[0] == 'index':\n",
    "            continue\n",
    "\n",
    "        # Check numbers if flag is set and remove numbers and  _ for titles\n",
    "        num_title = title.split('_', 1)\n",
    "        if num_title[0].isdigit():\n",
    "            title = num_title[-1]\n",
    "        elif NUMBERED_ONLY:\n",
    "            continue\n",
    "        entry['title'] = title.replace('_', ' ')\n",
    "        \n",
    "        # Get the full path of the file\n",
    "        new_dirname = os.path.join(dirname, key)\n",
    "        \n",
    "        # If the entry is a folder, recursively go into it\n",
    "        if value is not None:\n",
    "            sections = files_to_yaml(new_dirname, value)\n",
    "            \n",
    "            # Skip if empty folder\n",
    "            if len(sections) == 0:\n",
    "                continue\n",
    "            entry['sections'] = sections\n",
    "        entry['file'] = new_dirname if value is None else os.path.join(new_dirname, 'index')\n",
    "\n",
    "        sub_yaml.append(entry)\n",
    "        \n",
    "    return sub_yaml\n",
    "\n",
    "toc_yaml = {\n",
    "    'format': 'jb-book',\n",
    "    'root': 'root',\n",
    "    'parts': [],\n",
    "}\n",
    "\n",
    "for chapter in CHAPTERS:\n",
    "    files = get_files(chapter)\n",
    "    \n",
    "    entry = {}\n",
    "    entry['caption'] = chapter\n",
    "    entry['numbered'] = 2\n",
    "    entry['chapters'] = files_to_yaml(chapter, files)\n",
    "    \n",
    "    toc_yaml['parts'].append(entry)\n",
    "toc_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_toc.yml', 'w') as file:\n",
    "    yaml.dump(toc_yaml, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d5b3d-8ab4-40d0-8b31-3dce53951e71",
   "metadata": {},
   "source": [
    "## Change every notebook's metadata to remove hidden cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6beac4-25b8-4e22-802e-1d053cfa3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nbformat\n",
    "\n",
    "def change_metadata(path):\n",
    "    notebook = nbformat.read(path, nbformat.NO_CONVERT)\n",
    "\n",
    "    changed = False\n",
    "    for cell in notebook.cells:\n",
    "        metadata = cell.get('metadata', {})\n",
    "        tags = set(metadata.get('tags', []))\n",
    "        jupyter = metadata.get('jupyter', {})\n",
    "\n",
    "        hiddens = [jupyter.get('source_hidden', False), jupyter.get('output_hidden', False)]\n",
    "        new_tags = tags - {'hide-cell', 'hide-input', 'hide-output', 'remove-cell', 'remove-input', 'remove-output'}\n",
    "        if all(hiddens):\n",
    "            new_tags.add('remove-cell')\n",
    "        elif hiddens[0]:\n",
    "            new_tags.add('remove-input')\n",
    "        elif hiddens[1]:\n",
    "            new_tags.add('remove-output')\n",
    "\n",
    "        if new_tags != tags:\n",
    "            cell['metadata']['tags'] = list(new_tags)\n",
    "            changed = True\n",
    "\n",
    "    if changed:\n",
    "        nbformat.write(notebook, path)\n",
    "        \n",
    "for chapter in CHAPTERS:        \n",
    "    notebook_paths = glob.glob(f'./{chapter}/**/*.ipynb', recursive=True)\n",
    "    for notebook_path in notebook_paths:\n",
    "        change_metadata(notebook_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af8f40-fcf6-4594-9ffe-fa402739ecf9",
   "metadata": {},
   "source": [
    "## Add last commited date to every notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1940adf4-ce36-4c8c-a5ae-222f065ca1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import datetime\n",
    "import nbformat\n",
    "from git import Repo\n",
    "\n",
    "def update_date_ipynb(path):\n",
    "    # Get ipynb commit history\n",
    "    repo = Repo('./')\n",
    "    commits = list(repo.iter_commits(paths=path))\n",
    "    \n",
    "    # Do nothing if the file is not commited\n",
    "    if len(commits) == 0:\n",
    "        return\n",
    "        \n",
    "    # Get ipynb first commit date\n",
    "    first_commit_time = commits[-1].committed_datetime.strftime('%m-%d-%Y')\n",
    "    \n",
    "    # Use today's date as the updated date\n",
    "    updated_time = datetime.datetime.now().strftime('%m-%d-%Y')\n",
    "            \n",
    "    # Format the date string\n",
    "    new_source = f'*Updated {updated_time} (First commited {first_commit_time})*'\n",
    "    \n",
    "    # The date cell is always the first one in the notebook\n",
    "    notebook = nbformat.read(path, nbformat.NO_CONVERT)\n",
    "    date_cell = notebook.cells[0]\n",
    "    \n",
    "    # Define the regex pattern used to determine the date cell\n",
    "    date_regex = '(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])-\\d{4}'\n",
    "    rest_regex = f'^\\*(Updated ){date_regex}( \\(First commited ){date_regex}\\)\\*$'\n",
    "    pattern = re.compile(rest_regex)\n",
    "    \n",
    "    # Write the date to the date cell if it doesn't exist\n",
    "    match = pattern.fullmatch(date_cell.source) \n",
    "    if date_cell.cell_type != 'markdown' or match == None:\n",
    "        date_cell = {\n",
    "            'cell_type': 'markdown',\n",
    "            'metadata': {},\n",
    "            'source': new_source,\n",
    "        }\n",
    "        notebook.cells.insert(0, nbformat.notebooknode.from_dict(date_cell))\n",
    "        nbformat.write(notebook, path)\n",
    "        \n",
    "        return\n",
    "        \n",
    "    # Write the date to the date cell if the sources of ipynb have been changed\n",
    "    nbdiff_outs = !nbdiff -s HEAD $path --no-color\n",
    "    if len(nbdiff_outs) > 0:\n",
    "        date_cell['source'] = new_source\n",
    "        nbformat.write(notebook, path)\n",
    "        \n",
    "        return\n",
    "        \n",
    "for chapter in CHAPTERS:        \n",
    "    notebook_paths = glob.glob(f'./{chapter}/**/*.ipynb', recursive=True)\n",
    "    for notebook_path in notebook_paths:\n",
    "        update_date_ipynb(notebook_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b411367-6050-4e12-a7f0-e6b692ecf725",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Append to conf.py to allow block math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f00418-1a84-4ca9-9312-b3fa461d15d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mWrote conf.py to /home/l1qiao/Projects/joeyonng-notebook\u001b[0m\n",
      "\u001b[01mRunning Sphinx v5.0.2\u001b[39;49;00m\n",
      "\u001b[01mmaking output directory... \u001b[39;49;00mdone\n",
      "[etoc] Changing master_doc to 'root'\n",
      "[etoc] Excluded 46 extra file(s) not in toc\n",
      "checking bibtex cache... out of date\n",
      "parsing bibtex file /home/l1qiao/Projects/joeyonng-notebook/references.bib... parsed 5 entries\n",
      "\u001b[01mmyst v0.18.1:\u001b[39;49;00m MdParserConfig(commonmark_only=False, gfm_only=False, enable_extensions=['colon_fence', 'dollarmath', 'linkify', 'substitution', 'tasklist'], disable_syntax=[], all_links_external=False, url_schemes=['mailto', 'http', 'https'], ref_domains=None, highlight_code_blocks=True, number_code_blocks=[], title_to_header=False, heading_anchors=None, heading_slug_func=None, footnote_transition=True, words_per_minute=200, sub_delimiters=('{', '}'), linkify_fuzzy_links=True, dmath_allow_labels=True, dmath_allow_space=True, dmath_allow_digits=True, dmath_double_inline=True, update_mathjax=True, mathjax_classes='tex2jax_process|mathjax_process|math|output_area')\n",
      "\u001b[01mmyst-nb v0.17.2:\u001b[39;49;00m NbParserConfig(custom_formats={}, metadata_key='mystnb', cell_metadata_key='mystnb', kernel_rgx_aliases={}, execution_mode='off', execution_cache_path='', execution_excludepatterns=[], execution_timeout=30, execution_in_temp=False, execution_allow_errors=False, execution_raise_on_error=False, execution_show_tb=False, merge_streams=False, render_plugin='default', remove_code_source=False, remove_code_outputs=False, code_prompt_show='Show code cell {type}', code_prompt_hide='Hide code cell {type}', number_source_lines=False, output_stderr='show', render_text_lexer='myst-ansi', render_error_lexer='ipythontb', render_image_options={}, render_figure_options={}, render_markdown_format='commonmark', output_folder='build', append_css=True, metadata_to_fm=False)\n",
      "Using jupyter-cache at: /home/l1qiao/Projects/joeyonng-notebook/_build/.jupyter_cache\n",
      "\u001b[01mbuilding [mo]: \u001b[39;49;00mtargets for 0 po files that are out of date\n",
      "\u001b[01mbuilding [html]: \u001b[39;49;00mtargets for 15 source files that are out of date\n",
      "\u001b[01mupdating environment: \u001b[39;49;00m[new config] 15 added, 0 changed, 0 removed\n",
      "\u001b[01mreading sources... \u001b[39;49;00m[100%] \u001b[35mroot\u001b[39;49;00m                                                  \n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Learning Theory/3_PAC_Learning.md: WARNING: duplicate definition label 'definition-0', other instance in /home/l1qiao/Projects/joeyonng-notebook/Learning Theory/2_Effective_Class_Size.md\u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Learning Theory/3_PAC_Learning.md: WARNING: duplicate definition label 'definition-1', other instance in /home/l1qiao/Projects/joeyonng-notebook/Learning Theory/2_Effective_Class_Size.md\u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Learning Theory/3_PAC_Learning.md: WARNING: duplicate theorem label 'theorem-2', other instance in /home/l1qiao/Projects/joeyonng-notebook/Learning Theory/2_Effective_Class_Size.md\u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Learning Theory/3_PAC_Learning.md: WARNING: duplicate theorem label 'theorem-3', other instance in /home/l1qiao/Projects/joeyonng-notebook/Learning Theory/2_Effective_Class_Size.md\u001b[39;49;00m\n",
      "\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n",
      "\u001b[01mpickling environment... \u001b[39;49;00mdone\n",
      "\u001b[01mchecking consistency... \u001b[39;49;00mdone\n",
      "\u001b[01mpreparing documents... \u001b[39;49;00mdone\n",
      "\u001b[01mwriting output... \u001b[39;49;00m[100%] \u001b[32mroot\u001b[39;49;00m                                                   \n",
      "\u001b[91mWARNING: Domain 'sphinx_proof.domain::prf' has not implemented a `resolve_any_xref` method [myst.domains]\u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Statistical Learning/1_Bayesian_Decision_Theory.ipynb:30006: WARNING: 'myst' reference target not found: \u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Statistical Learning/1_Bayesian_Decision_Theory.ipynb:30008: WARNING: 'myst' reference target not found: \u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Statistical Learning/1_Bayesian_Decision_Theory.ipynb:30010: WARNING: 'myst' reference target not found: \u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Statistical Learning/1_Bayesian_Decision_Theory.ipynb:30012: WARNING: 'myst' reference target not found: \u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Statistical Learning/4_Expectation_Maximization.ipynb:30006: WARNING: 'myst' reference target not found: \u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Statistical Learning/4_Expectation_Maximization.ipynb:30008: WARNING: 'myst' reference target not found: \u001b[39;49;00m\n",
      "\u001b[91m/home/l1qiao/Projects/joeyonng-notebook/Supervised Learning/0_Linear_Discriminant.ipynb:20006: WARNING: 'myst' reference target not found: affine-projection\u001b[39;49;00m\n",
      "\u001b[01mgenerating indices... \u001b[39;49;00mgenindex prf-prf done\n",
      "\u001b[01mwriting additional pages... \u001b[39;49;00msearch done\n",
      "\u001b[01mcopying static files... \u001b[39;49;00mdone\n",
      "\u001b[01mcopying extra files... \u001b[39;49;00mdone\n",
      "\u001b[01mdumping search index in English (code: en)... \u001b[39;49;00mdone\n",
      "\u001b[01mdumping object inventory... \u001b[39;49;00mdone\n",
      "[etoc] missing index.html written as redirect to 'root.html'\n",
      "sitemap.xml was generated for URL https://joeyonng.github.io/joeyonng-notebook/ in /home/l1qiao/Projects/joeyonng-notebook/_build/html/sitemap.xml\n",
      "\u001b[01mbuild succeeded, 26 warnings.\u001b[39;49;00m\n",
      "\n",
      "The HTML pages are in _build/html.\n"
     ]
    }
   ],
   "source": [
    "!rm -r _build\n",
    "!jupyter-book config sphinx .\n",
    "\n",
    "settings = ['suppress_warnings = [\"myst.header\"]', 'myst_dmath_double_inline = True']\n",
    "with open('conf.py', 'a') as file:\n",
    "    file.write('\\n# Belows are more customized settings')\n",
    "    for setting in settings:\n",
    "        file.write(f'\\n{setting}')\n",
    "    \n",
    "!sphinx-build . ./_build/html/ -b html\n",
    "!rm conf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27b192-4425-45f0-ba28-83f6ebf9a587",
   "metadata": {},
   "source": [
    "## Push the build html pages to gh-pages branch on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a60eec0c-b45d-4472-8660-6664ef9bf092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 27, done.\n",
      "Counting objects: 100% (27/27), done.\n",
      "Delta compression using up to 64 threads\n",
      "Compressing objects: 100% (15/15), done.\n",
      "Writing objects: 100% (15/15), 8.06 KiB | 2.69 MiB/s, done.\n",
      "Total 15 (delta 10), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (10/10), completed with 10 local objects.\u001b[K\n",
      "To https://github.com/Joeyonng/joeyonng-notebook.git\n",
      "   eeb06f0..517c444  gh-pages -> gh-pages\n"
     ]
    }
   ],
   "source": [
    "# If it needs to input the password, run this command in a terminal \n",
    "!ghp-import -n -p -f _build/html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
