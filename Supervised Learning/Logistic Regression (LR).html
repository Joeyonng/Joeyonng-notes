<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>joeyonng-notebook - Logistic Regression (LR)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">
      Joeyonng's Notebook
      </li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Joeyonngâ€™s Notebook</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Learning Theory</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/1_Statistical_Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/2_Effective_Class_Size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Effective Class Size</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/3_PAC_Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PAC Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/4_Agnostic_Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Agnostic Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/5_Rademacher_Complexity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rademacher Complexity</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Statistical Learning</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Statistical Learning/1_Bayesian_Decision_Theory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Decision Theory (BDT)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Statistical Learning/2_Maximum_Likelihood_Estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Maximum Likelihood Estimation (MLE)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Statistical Learning/3_Bayesian_Estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Estimation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Statistical Learning/4_Expectation_Maximization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Expectation-maximization</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../ML Q&amp;A.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ML Q &amp; A</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#preliminary" id="toc-preliminary" class="nav-link active" data-scroll-target="#preliminary">Preliminary</a>
  <ul class="collapse">
  <li><a href="#optimization" id="toc-optimization" class="nav-link" data-scroll-target="#optimization">Optimization</a></li>
  </ul></li>
  <li><a href="#linear-regression-for-regression-problems" id="toc-linear-regression-for-regression-problems" class="nav-link" data-scroll-target="#linear-regression-for-regression-problems">## Linear regression for regression problems</a>
  <ul class="collapse">
  <li><a href="#linear-function" id="toc-linear-function" class="nav-link" data-scroll-target="#linear-function">Linear function</a></li>
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function">Loss function</a></li>
  <li><a href="#regularization" id="toc-regularization" class="nav-link" data-scroll-target="#regularization">Regularization</a></li>
  </ul></li>
  <li><a href="#solving-linear-regression" id="toc-solving-linear-regression" class="nav-link" data-scroll-target="#solving-linear-regression">Solving linear regression</a></li>
  <li><a href="#solving-linear-regression-1" id="toc-solving-linear-regression-1" class="nav-link" data-scroll-target="#solving-linear-regression-1">Solving linear regression</a></li>
  <li><a href="#logistic-regression-for-classification-problems" id="toc-logistic-regression-for-classification-problems" class="nav-link" data-scroll-target="#logistic-regression-for-classification-problems">## Logistic regression for classification problems</a>
  <ul class="collapse">
  <li><a href="#from-regression-to-classification-using-sigmoid-function" id="toc-from-regression-to-classification-using-sigmoid-function" class="nav-link" data-scroll-target="#from-regression-to-classification-using-sigmoid-function">From regression to classification using sigmoid function</a></li>
  <li><a href="#binary-cross-entropy-log-loss-instead-of-mean-squared-error" id="toc-binary-cross-entropy-log-loss-instead-of-mean-squared-error" class="nav-link" data-scroll-target="#binary-cross-entropy-log-loss-instead-of-mean-squared-error">Binary cross entropy (log loss) instead of mean squared error</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Logistic Regression (LR)</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<hr>
<ol type="1">
<li>Linear regression is a supervised machine learning model that fits a correlation linear line between input and label variables. The output value can be arbitrary continuous value and thus it is used for regression.</li>
<li>The model has a weight vector and a bias as parameters. The output of the model is the dot product of the weight vector and the input vector plus a bias value.</li>
<li>The linear regression model is trained by solving an optimization problem that is defined by applying a cost function that evaluates the difference between the modelâ€™s output and the correct labels. The cost function for linear regression is mean squared error function that takes the mean of the squared value of each predictionâ€™s error. MSE for linear regression is proved to be convex, so solving it using convex optimization or gradient descent will get the global minimum.</li>
<li>Logistic regression is similar to linear regression, but the output is a probability value between 0 and 1, so it is used for binary classification instead of regression.</li>
<li>A sigmoid (logistic) function is attached after the output of linear regression to output a probability for logistic regression. Instead of using MSE, the cost function is changed to binary cross entropy such that the loss grows exponentially with the difference between outputs and labels.</li>
</ol>
<section id="preliminary" class="level2">
<h2 class="anchored" data-anchor-id="preliminary">Preliminary</h2>
<hr>
<section id="optimization" class="level3">
<h3 class="anchored" data-anchor-id="optimization">Optimization</h3>
<section id="convex-function" class="level4">
<h4 class="anchored" data-anchor-id="convex-function">Convex function</h4>
<blockquote class="blockquote">
<p>TODO</p>
</blockquote>
</section>
<section id="gradient-descent" class="level4">
<h4 class="anchored" data-anchor-id="gradient-descent">Gradient descent</h4>
<blockquote class="blockquote">
<p>TODO</p>
</blockquote>
</section>
</section>
</section>
<section id="linear-regression-for-regression-problems" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-for-regression-problems">## Linear regression for regression problems</h2>
<section id="linear-function" class="level3">
<h3 class="anchored" data-anchor-id="linear-function">Linear function</h3>
<p>If a function with single input and output <span class="math inline">y = f(x)</span> is a linear function, it represents a straight line on the coordinate plane. Thus it has the form:</p>
<p><span class="math display"> y = wx + b </span></p>
<p>where <span class="math inline">w</span> is the slope and <span class="math inline">b</span> is the y-intercept of the line.</p>
<p>A linear function can also take multiple inputs and we can represent <span class="math inline">n</span> inputs with a vector <span class="math inline">\mathbf{x} \in \mathbb{R}^{d}</span>. Then the equation changes to:</p>
<p><span class="math display"> y = \mathbf{w} \cdot \mathbf{x} + b </span></p>
<p>where <span class="math inline">\mathbf{w} \in \mathbb{R}^{d}</span> is called <strong>weights</strong> or the weight vector and <span class="math inline">b \in \mathbb{R}</span> is called <strong>bias</strong>.</p>
<p>Linear regression is a supervised regression model that simply fits a linear function between the inputs <span class="math inline">\mathbf{x}</span> and output <span class="math inline">y</span>.</p>
</section>
<section id="loss-function" class="level3">
<h3 class="anchored" data-anchor-id="loss-function">Loss function</h3>
<p>Loss function is a function that measures the error between the labels predicted by your current model and the true labels for a set of instances (training set).</p>
<p>Linear regression minimizes the a particular loss function called <strong>mean squared error (MSE)</strong> function. Given a set of training labels <span class="math inline">\mathbf{y} = y_{1}, y_{2}, \dots, y_{n}</span> for <span class="math inline">n</span> training instances and the predicted labels <span class="math inline">\hat{\mathbf{y}} = \hat{y}_{1}, \hat{y}_{2}, \dots, \hat{y}_{n}</span> for the same instances, MSE is defined as:</p>
<p><span class="math display"> \operatorname{MSE}(\hat{\mathbf{y}}, \mathbf{y}) = \frac{1}{n} \sum_{i}^{n}(\hat{y}_{i} - y_{i})^{2} </span></p>
<p>Thus, fitting a linear regression model for a training set <span class="math inline">\mathbf{X} \in \mathbb{R}^{n \times d}</span> with labels <span class="math inline">\mathbf{y} \in \mathbb{R}^{n}</span> is a convex optimization problem:</p>
<p><span class="math display">
\begin{align}
\min &amp; \quad \lVert (\mathbf{X}\mathbf{w} + b) - \mathbf{y} \rVert_{2}^{2} \\
= \min &amp; \quad \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} \\
\end{align}
</span></p>
</section>
<section id="regularization" class="level3">
<h3 class="anchored" data-anchor-id="regularization">Regularization</h3>
<p>Regularization is a technique used to avoid over-fitting of the machine learning models. Regularization works by adding an additional penalty term in the loss function to penalize aspects of the model other than the prediction error.</p>
<p><span class="math display"> L_{\text{new}} = L_{\text{old}} + \lambda L_{\text{reg}} </span></p>
<p>where <span class="math inline">\lambda</span> is a hyperparamter that adjust the trade-off between the primary objective and the regularization.</p>
<p>For linear regression and other many models, usually <span class="math inline">L_{2}</span> regularization (Ridge) and <span class="math inline">L_{1}</span> regularization (Lasso) are used. - Ridge penalizes the <span class="math inline">L_{2}</span> norm of the weights</p>
<p><span class="math display">
\begin{align}
L_{\text{ridge}} &amp; = \lVert \mathbf{w} \rVert_{2}^{2} \\
&amp; = \sum_{i=1}^{\lvert \mathbf{w} \rvert} w_{i}^{2} \\
\end{align}
</span></p>
<ul>
<li>Lasso penalizes the <span class="math inline">L_{1}</span> norm of the weights</li>
</ul>
<p><span class="math display">
\begin{align}
L_{\text{lasso}} &amp; = \lVert \mathbf{w} \rVert_{1} \\
&amp; = \sum_{i=1}^{\lvert \mathbf{w} \rvert} \lvert w_{i} \rvert \\
\end{align}
</span></p>
<p>Both Ridge and Lasso penalize the magnitude of the weights. Large weights tend to overfit the training dataset because &gt; TODO</p>
</section>
</section>
<section id="solving-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="solving-linear-regression">Solving linear regression</h2>
<hr>
<p>Here we show how we can analytically solve linear regression to get a closed form solution.</p>
<p>We first make <span class="math inline">b</span> as part of <span class="math inline">\mathbf{w}</span> to simplify the derivation process, which is done by adding <span class="math inline">b</span> as an extra weight into <span class="math inline">\mathbf{w}</span> vector. The result weight vector <span class="math inline">\mathbf{\hat{w}} \in \mathbb{R}^{d + 1}</span> has one extra dimension:</p>
<p><span class="math display"> \mathbf{\hat{w}} = (b, w_{1}, w_{2}, \dots, w_{d}). </span></p>
<p>Then we add a dummy input <span class="math inline">x_{0} = 1</span> to all input instances, so that</p>
<p><span class="math display"> \mathbf{\hat{x}} = (1, x_{1}, x_{2}, \dots, x_{d}). </span></p>
<p>As a result, we have</p>
<p><span class="math display"> \mathbf{\hat{w}} \cdot \mathbf{\hat{x}} = \mathbf{w} \cdot \mathbf{x} + b. </span></p>
<p>The equation that we want to solve is</p>
<p><span class="math display"> \min \quad \frac{1}{n} \sum_{i=1}^{n} (\mathbf{\hat{w}} \cdot \mathbf{\hat{x}}_{i} - y_{i})^{2} + \lambda \lVert \mathbf{w} \rVert_{2}^{2} </span></p>
<p>Since this equation is a convex function, it can be directly solved by setting its derivative w.r.t its parameters (<span class="math inline">\mathbf{\hat{w}})</span> to 0.</p>
</section>
<section id="solving-linear-regression-1" class="level2">
<h2 class="anchored" data-anchor-id="solving-linear-regression-1">Solving linear regression</h2>
<p>Here we show how we can analytically solve linear regression with <span class="math inline">L_{2}</span> regularization to get a closed form solution.</p>
<p><span class="math display"> \min \quad \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} + \lambda \lVert \mathbf{w} \rVert_{2}^{2} </span></p>
<p>Since this equation is a convex function, it can be directly solved by taking its derivative w.r.t its parameters (<span class="math inline">\mathbf{w}</span> and <span class="math inline">b</span>).</p>
<p><span class="math display">
\begin{align}
\frac{\partial}{\partial \mathbf{w}_{j}} \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial \mathbf{w}_{j}} \frac{1}{n} \sum_{i=1}^{n} (\mathbf{w} \cdot \mathbf{x}_{i} + (b - y_{i}))^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{2}{n} \sum_{i=1}^{n} \mathbf{x}_{i, j} (\mathbf{w} \cdot \mathbf{x}_{i} + (b - y_{i})) + 2 \lambda \mathbf{w}_{j} &amp; = 0 \\
\end{align}
</span></p>
<p><span class="math display">
\begin{align}
\frac{\partial}{\partial \mathbf{w}} \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial \mathbf{w}} \frac{1}{n} \sum_{i=1}^{n} (\mathbf{w} \cdot \mathbf{x}_{i} + (b - y_{i}))^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial \mathbf{w}} \frac{1}{n} \sum_{i=1}^{n} (\mathbf{w} \cdot \mathbf{x}_{i})^{2} + 2(\mathbf{w} \cdot \mathbf{x}_{i})(b - y_{i}) + (b - y_{i})^{2} + \lambda \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{1}{n} \sum_{i=1}^{n} 2(\mathbf{x}_{i} \cdot \mathbf{x}_{i})\mathbf{w} + 2\mathbf{x}_{i}(b - y_{i}) + 2 \lambda \mathbf{w} &amp; = 0\\
\frac{2 \mathbf{w}}{n} \sum_{i=1}^{n} \mathbf{x}_{i} \cdot \mathbf{x}_{i} + \frac{2b}{n} \sum_{i=1}^{n} \mathbf{x}_{i} - \frac{2}{n} \sum_{i=1}^{n} \mathbf{x}_{i} y_{i} + 2 \lambda \mathbf{w} &amp; = 0 \\
\end{align}
</span></p>
<blockquote class="blockquote">
<p>TODO</p>
</blockquote>
<p><span class="math display">
\begin{align}
\frac{\partial}{\partial b} \frac{1}{n} \sum_{i=1}^{n} ((\mathbf{w} \cdot \mathbf{x}_{i} + b) - y_{i})^{2} + \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial b} \frac{1}{n} \sum_{i=1}^{n} (b + (\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}))^{2} + \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{\partial}{\partial b} \frac{1}{n} \sum_{i=1}^{n} b^{2} + 2b(\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}) + (\mathbf{w} \cdot \mathbf{x}_{i} - y_{i})^{2} + \lVert \mathbf{w} \Vert_{2}^{2} &amp; = 0 \\
\frac{1}{n} \sum_{i=1}^{n} 2b + 2(\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}) &amp; = 0 \\
2b + \frac{2}{n} \sum_{i=1}^{n} ï¼ˆ\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}) &amp; = 0 \\
b &amp; = - \frac{1}{n} \sum_{i=1}^{n} ï¼ˆ\mathbf{w} \cdot \mathbf{x}_{i} - y_{i}) \\
\end{align}
</span></p>
</section>
<section id="logistic-regression-for-classification-problems" class="level2">
<h2 class="anchored" data-anchor-id="logistic-regression-for-classification-problems">## Logistic regression for classification problems</h2>
<section id="from-regression-to-classification-using-sigmoid-function" class="level3">
<h3 class="anchored" data-anchor-id="from-regression-to-classification-using-sigmoid-function">From regression to classification using sigmoid function</h3>
<p>How can we use linear regression on a binary classification problem where the labels are 0 and 1?</p>
<p>Answer: take the output of a linear regression model and pass it to a <strong>sigmoid</strong> (logistic) function:</p>
<p><span class="math display"> \sigma(x) = \mathrm{sigmoid}(x) = \frac{1}{1 + e^{-x}} </span></p>
<p>Sigmoid function has the following characterstics that are suitable for binary classification 1. Sigmoid function maps range <span class="math inline">(-\inf, \inf)</span> to range <span class="math inline">(0, 1)</span>, which can be interpreted as the possibility of being class 1. 1. Positive inputs map to output larger than 0.5 and negative inputs map to output less than 0.5.</p>
<p>Thus, given an instance <span class="math inline">\mathbf{x}</span>, the binary output can be derived by setting a threshold <span class="math inline">\theta</span> (usually set to <span class="math inline">0.5</span>) to the output of the logistic regression,</p>
<p><span class="math display"> \hat{y} = \sigma(\mathbf{w}\mathbf{x} + b) </span></p>
<p><span class="math display">
\hat{y}_{\text{label}} =
\begin{cases}
1, &amp; \hat{y} \geq \theta \\
0, &amp; \hat{y} &lt; \theta \\
\end{cases}
</span></p>
<p>Note another commonly used function is <strong>logit</strong> function,</p>
<p><span class="math display"> \sigma^{-1}(x) = \mathrm{logit}(x) = \log \frac{x}{1 - x} </span></p>
<p>The inverse of the sigmoid function is the logit function, which can be derived by exchange the input and the output of the sigmoid function:</p>
<p><span class="math display">
\begin{align}
x &amp;= \frac{1}{1 + e^{-y}} \\
\frac{1}{x} &amp;= 1 + e^{-y} \\
e^{-y} &amp;= \frac{1 - x}{x} \\
e^{y} &amp;= \frac{x}{1 - x} \\
y &amp;= \log\frac{x}{1 - x} \\
\end{align}
</span></p>
</section>
<section id="binary-cross-entropy-log-loss-instead-of-mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="binary-cross-entropy-log-loss-instead-of-mean-squared-error">Binary cross entropy (log loss) instead of mean squared error</h3>
<p>Although sigmoid function can work for binary classification problem, it doesnâ€™t work quite well with MSE loss. The primary reason is that MSE with sigmoid function is not a convex function anymore.</p>
<p><span class="math display"> L_{\text{MSE}} = \frac{1}{n} \sum_{i}^{n} (\frac{1}{1 + e^{-(\mathbf{w}\mathbf{x} + b)}} -y_{i})^{2} = \frac{1}{n} \sum_{i}^{n} (\sigma(\mathbf{w}\mathbf{x} + b) -y_{i})^{2} </span></p>
<p>To prove a function is convex or not, one way is to see if the second derivative of <span class="math inline">L_{\text{MSE}}</span> w.r.t to <span class="math inline">\mathbf{w}</span> is positive semidefinite.</p>
<p><span class="math display">
\begin{align}
\frac{\partial L_{\text{MSE}}}{\partial \mathbf{w}} &amp; = \frac{\partial L_{\text{MSE}}}{\partial \sigma} \frac{\partial \sigma}{\partial \mathbf{w}} &amp; \text{[chain rule]} \\
&amp; = \frac{\partial}{\partial \sigma} \left( \frac{1}{n} \sum_{i}^{n} (\sigma -y_{i})^{2} \right) \sigma(1 - \sigma) \mathbf{x} &amp; \text{[$\sigma' = \sigma(1 - \sigma)$]} \\
&amp; = \frac{2}{n} \sum_{i}^{n} (\sigma - y_{i}) \sigma(1 - \sigma) \mathbf{x} \\
&amp; = \frac{2 \mathbf{x}}{n} \sum_{i}^{n} \sigma^{2} - \sigma^{3} - y_{i}\sigma - y_{i}\sigma^{2}  \\
\end{align}
</span></p>
<p><span class="math display">
\begin{align}
\frac{\partial^{2} L_{\text{MSE}}}{\partial \mathbf{w}^{2}} &amp; = \frac{\partial}{\partial \mathbf{w}} \left( \frac{2 \mathbf{x}}{n} \sum_{i}^{n} \sigma^{2} - \sigma^{3} - y_{i}\sigma - y_{i}\sigma^{2} \right) \\
&amp; = \frac{\partial}{\partial \sigma} \left( \frac{2 \mathbf{x}}{n} \sum_{i}^{n} \sigma^{2} - \sigma^{3} - y_{i}\sigma - y_{i}\sigma^{2} \right) \frac{\partial \sigma}{\partial \mathbf{w}}^{T} \\
&amp; = \left( \frac{2 \mathbf{x}}{n} \sum_{i}^{n} 2\sigma - 3\sigma^{2} - y_{i} - 2y_{i}\sigma \right) \sigma(1 - \sigma) \mathbf{x}^{T} \\
\end{align}
</span></p>
<blockquote class="blockquote">
<p>TODO: prove the hessian matrix is not positive semidefinite.</p>
</blockquote>
<p>Thus, instead of MSE, <strong>binary cross entropy</strong> (BCE) loss (log loss) is used with sigmoid to create a convex objective.</p>
<p><span class="math display"> \mathrm{BCE} = -\frac{1}{n}\sum_{i}^{n}(y_{i}\log(\hat{y}_{i}) + (1-y_{i})\log(1-\hat{y}))) </span></p>
<p>BCE assumes both inputs <span class="math inline">y</span> and <span class="math inline">\hat{y}</span> are in the range <span class="math inline">[0, 1]</span>. Since normally the labels <span class="math inline">y_{i}</span> are 0 or 1, BCE can be interpreted by decomposing to two cases for each prediction and label pair:</p>
<p><span class="math display">
\begin{cases}
-\log(\hat{y}_{i}) &amp;  y_{i} = 1 \\
-\log(1 - \hat{y}_{i}) &amp; y_{i} = 0 \\
\end{cases}
</span></p>
<div class="cell" data-tags="[&quot;remove-input&quot;]" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> IFrame</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>IFrame(<span class="st">"https://www.desmos.com/calculator/ojpmcptvt0?embed"</span>, width<span class="op">=</span><span class="dv">500</span>, height<span class="op">=</span><span class="dv">500</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">

        <iframe width="500" height="500" src="https://www.desmos.com/calculator/ojpmcptvt0?embed" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<hr>
<ol type="1">
<li>https://towardsdatascience.com/why-not-mse-as-a-loss-function-for-logistic-regression-589816b5e03c</li>
<li>https://www.cs.toronto.edu/~rgrosse/courses/csc311_f20/readings/notes_on_linear_regression.pdf</li>
</ol>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>