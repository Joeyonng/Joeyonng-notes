{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef83d871-a27c-427c-888d-3e694b8ef84f",
   "metadata": {},
   "source": [
    "# MLIC IMLI\n",
    "\n",
    "*04-11-2022*\n",
    "\n",
    "This page contains my reading notes on \n",
    "\n",
    "- [**MLIC: A MaxSAT-Based Framework for Learning Interpretable Classification Rules**](https://www.semanticscholar.org/paper/MLIC%3A-A-MaxSAT-Based-Framework-for-Learning-Rules-Malioutov-Meel/d4294e394f9fad9bc29e4c8b5d653ff9b2dfbca8)\n",
    "- [**IMLI: An Incremental Framework for MaxSAT-Based Learning of Interpretable Classification Rules**](https://www.semanticscholar.org/paper/IMLI%3A-An-Incremental-Framework-for-MaxSAT-Based-of-Ghosh-Meel/f52d22d1bb0394b7c26d955a6bbadbfe7f60d191)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c23f299-6c58-43ed-86e9-dfdf0923d2f6",
   "metadata": {},
   "source": [
    "## Satisfiability problem (SAT)\n",
    "Let $\\{C_{1}, \\dots, C_{m}\\}$ be a set of Boolean clauses on variables $x_{1}, \\dots, x_{n}$ where each clause is a disjunction of literals, each literal being a Boolean variable or its negation. SAT is the problem of finding an assignment of the boolean variables that makes all clauses true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3f142-02a1-4b55-a3e1-3bf72187f2cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "#### Maximum satisfiability problem (MaxSAT)\n",
    "\n",
    "Let there be a nonnegative weight $W(C) = w_{c}$ associated with each clause. MaxSAT is the problem of finding an assignment of the boolean variables that maximizes the total weight of the satisfied clauses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b5b35a-89ed-413a-90a0-0848eb8c29b1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Partial MaxSAT problem\n",
    "\n",
    "Let $\\{C_{1}, \\dots, C_{m}\\}$ consist of *soft* clauses and *hard* clauses. Let there be a nonnegative weight $W(C) = w_{c}$ associated with each soft clause. Partial MaxSAT is the problem of finding an assignment to the boolean variables that makes all hard clauses true and maximizes the total weight of the satisfied soft clauses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc81f9c-ffc0-46c0-a9fc-75d8a9dfe7af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem formulation\n",
    "\n",
    "Inputs:\n",
    "\n",
    "1. Binary matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times m}$ of $n$ instances with $m$ binary features.\n",
    "1. Binary vector $\\mathbf{y} \\in \\mathbb{R}^{n}$ of $n$ binary labels.\n",
    "1. Integer $k$ indicating the number of clauses in the CNF rule\n",
    "1. Regularization parameter $\\lambda$.\n",
    "\n",
    "Outputs:\n",
    "\n",
    "1. a CNF rule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c280b-c229-4565-8431-795dd06f582e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Variables:\n",
    "\n",
    "1. $k \\times m$ binary matrix $\\mathbf{B}$ of the variables $\\{b_{1, 1}, b_{1, 2}, \\dots, b_{1, m}, \\dots, b_{k, m}\\}$ that represents the result CNF rule. \n",
    "    1. $\\mathbf{B}_{l, j} = 1$ means that the feature $f_{j}$ appears in clause $C_{i}$ of the CNF rule. \n",
    "    1. $\\mathbf{B}_{l}$ means the $l$th row of the matrix $\\mathbf{B}$, which is also the $l$th clause $C_{l}$.\n",
    "1. $n$ binary noise variables $\\{\\eta_{1}, \\dots, \\eta_{n}\\}$ that indicates the instances that can be treated as noise.\n",
    "    1. If $\\eta_{i} = 1$, the results CNF rule doesn't have to classifies the $\\mathbf{x}_{i}$ correctly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d192ed5-a59b-4f7f-a80a-5b75badbb678",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Partial MaxSAT formulation:\n",
    "\n",
    "1. CNF constraint\n",
    "\n",
    "    $$ Q = \\bigwedge_{i=1}^{n} N_{i} \\wedge \\bigwedge_{i=1, j=1}^{i=k, j=m} V_{i, j} \\wedge \\bigwedge_{i=1}^{n} D_{i}  $$\n",
    "    \n",
    "1. We want the training accuracy to be higher. Each non-noise will have a $\\lambda$ weight. (soft clauses)\n",
    "\n",
    "    $$ N_{i} = \\neg \\eta_{i} \\quad W(N_{i}) = \\lambda $$\n",
    "    \n",
    "1. We want the CNF rule to be sparse. Each don't care literal will have a $1$ weight. (soft clauses)\n",
    "\n",
    "    $$ V_{l, j} = \\neg \\mathbf{B}_{l, j} \\quad W(V_{l, j}) = 1 $$\n",
    "\n",
    "1. We want each non-noise instance to be correctly classified by the CNF rule. (hard clauses)\n",
    "\n",
    "    $$ D_{i} = \\left( \\neg \\eta_{q} \\rightarrow \\left( y_{i} \\leftrightarrow \\bigwedge_{l = 1}^{k} \\left( \\bigvee_{j=1}^{m} \\mathbf{X}_{i, j} \\wedge \\mathbf{B}_{l, j} \\right) \\right) \\right) \\quad W(D_{i}) = \\infty $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
